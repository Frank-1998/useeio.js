<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <title>Open Footprint - EEIO Labels</title>
  <link rel="shortcut icon" href="data:image/x-icon;," type="image/x-icon">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <script type="text/javascript" src="/localsite/js/localsite.js?showheader=true"></script>
  <link rel="stylesheet" href="/localsite/css/base.css" id="/localsite/css/base.css" />
  <!--
  <link rel="stylesheet" href="../node_modules/mocha/mocha.css" />
  -->
</head>

<body>

  <!-- Try uncommenting after doing install for node-modules 
  Also uncomment mocha.css above.
  -->
  <!--
  <div id="mocha"></div>
  <script src="../node_modules/mocha/mocha.js"></script>
  <script src="../node_modules/chai/chai.js"></script>
  <script src="../dist/useeio.js"></script>

  <script class="mocha-init">
    var assert = chai.assert;
    var expect = chai.expect;
    var webApi = new useeio.WebApi({
      endpoint: 'http://localhost:8080/api',
      asJsonFiles: true,
    });
    mocha.setup('bdd');
  </script>

<script src="model-requests.js"></script>
<script src="matrix-requests.js"></script>

  <script class="mocha-exec">
    mocha.run();
  </script>
  -->
<script>
loadMarkdown("tables.md", "tablesDiv", "_parent");
loadMarkdown("schema.md", "schemaDiv", "_parent");
loadText("../../OpenFootprint/impacts/exiobase/US-source/create-database.yaml", "yamlDiv", "_parent");
loadMarkdown("README.md", "readmeDiv", "_parent");
</script>

<style>
  a {
    text-decoration:none;
    color: #0366d6;
  }
  a:hover {
    text-decoration: underline;
  }

  td {
    border: 1px solid #ccc;
    padding:  5px;
  }
  th,td {
    align: left;
  }
</style>


<div class="content contentpadding">

<a href="/OpenFootprint">Open Footprint Panels</a><br>
<h1>USEEIO Open Footprint Data + Exiobase</h1>

IN PROGRESS - Sahil, Himanshu and Sridevi are sending data to <a href="https://duckdb.org/docs/api/r.html">DuckDB</a> and <a href="https://supabase.com">Supabase</a> for Countries, States and the Earth.<br><br>

<a href="https://colab.research.google.com/drive/1Wm9Bvi9pC66xNtxKHfaJEeIYuXKpb1TA?usp=sharing">CoLab</a> - TO DO: Implement .csv pull from GitHun and add Supabase table inserts
Our upcoming <a href="/OpenFootprint/impacts/">Vanilla JavaScript DuckDB Starter</a><br>
<a href="https://model.earth/storm/impact/process.html">SQL Documentation Sample - Storm Tweet Data</a><br><br>

We <a href="https://github.com/ModelEarth/USEEIO/tree/import_factors/import_factors_exio">generate_import_factors.py</a> which combines US BEA and <a href="https://exiobase.eu">EXIOBASE</a> data emissions factors for annual trade data. Exiobase provides the equivalent to <a href="https://github.com/USEPA/useeior/blob/master/format_specs/Model.md">M, N, and x</a> which is used in USEEIO models for import emissions factors. Exiobase also provides gross trade data which has no equivalent in USEEIO. Checkout our upcoming SQL Table structure below.<br><br>

<div style="float:left; max-width:400px; margin-right:40px">

<a href="https://github.com/modelearth/useeio.js">USEEIO.js GitHub Repo</a> and 
<a href="https://smmtool.app.cloud.gov/">API</a><br><br>

<b>Chart Starters</b><br>

<a href="../../OpenFootprint/trade/">Trade Flow Map</a><br>
<a href="../charts/d3/chord-diagram/">Chord (D3)</a><br><!-- https://nivo.rocks/chord/ -->
<a href="../charts/echarts/sankey-nodeAlign-left.html">Sankey (eCharts)</a><br><br>

<b>Label Samples</b><br>
<a href="/io/template/">Footprint Builder</a><br>
<a href="/OpenFootprint/">Open Footprint Data</a><br><br>

<b>Environmentally Extended Input-Output (EEIO)</b><br>

<a href="/data-pipeline/research/economy/">US and All 50 States</a> - <a href="https://github.com/ModelEarth/OpenFootprint/tree/main/impacts/2020">Data Source</a><br><br>

<a href="calculation.html">Impact Calculation</a><br>
<a href="tabulator.html">Commodities</a></a><br>
<a href="commodity_vector.html">Commodity Vector</a><br>
<a href="demands.html">Demands</a><br>
<a href="model_info.html">Model Info</a><br>
<a href="naics_map.html">Naics Map</a><br>
<a href="sector_crosswalk.html">Sector Crosswalk</a><br>
<a href="sector_profile.html">Sector Profile</a><br>
<a href="sector_purchase_impacts.html">Sector Purchase Impacts</a><br>
<a href="sector_scopes.html">Sector Scopes</a><br>
<a href="sector_supply_impacts.html">Sector Supply Impacts</a><br>
<a href="matrix-requests.js">Matrix Requests (js)</a><br>
<a href="model-requests.js">Model Requests (js)</a><br>
<br>

Some of the above samples only send json to the console.log, so view with your browser's inspector.<br><br>

TO DO: Use the function formatCell() in config.js to make numbers simple in the pages above (42.2 Billion, etc.). The config.js file is included in all the pages above.<br><br>

TO DO: Create a toggle to move between the simple number display, full numbers and scietific notation. Place in the upper right above a <a href="tabulator.html">tabulator.html</a> on all the pages above and hide the two extra columns.<br><br>

TO DO: Use <a href="https://github.com/ModelEarth/USEEIO/tree/import_factors/import_factors_exio">generate_import_factors.py</a> to run 2012 to 2016. Try with 2017 schema, and compare to 2012 schema to see if the older data needs it for the sector/commodity names.<br><br> 

TO DO: Pull SQL into our <a href="../../OpenFootprint/trade/">trade flow map</a>. Here's another <a href="https://github.com/ModelEarth/trademapper-js">trade flow map</a> we can expand. It's visible at <a href="https://trademapper.co.uk">trademapper.co.uk</a> with sample data in their <a href="https://github.com/trademapper/trademapper-js/wiki/How-to-use-trademapper">GitHub Wiki</a>.

</div>


<div style="overflow: auto;">
<!-- USEEIOR - standard for model objects -->

<b>SQL table names</b> - visualized within our <a href="https://model.earth/io/about/matrix/">Matrix Details</a><br>
<a href="https://github.com/USEPA/useeior/blob/master/format_specs/Model.md">USEEIOR model objects</a>
<br><br>

An underscore separates the row and column names.<br>
<a href="/OpenFootprint/impacts/2020/">View 2020 Data</a> (json pulled from API)<br><br>

<div id="tablesDiv"></div>

</div>

<div style="clear:both"></div>
<br>

<style>
#schemaDiv strong {
  font-size: 16px;
}
.yamlPre {
  background-color: #eee;
  padding: 20px;
  overflow-y: scroll;
}
.dark .yamlPre {
  background-color: #222;
}
</style>
<div id="schemaDiv"></div>

Integrate Python from <a href="https://chatgpt.com/share/3a89cc73-c839-4592-bc6e-e82a6a8e400b">From ChatGPT</a> - Python also resides in a hidden comment.<br><br>

Commodity.csv for CommodityNames from <a href="https://www.bea.gov/industry/input-output-accounts-data">BEA input-output (ImportMatrices_Before_Redefinitions_DET_2017.xlsx</a>.<br>
TO DO: From BEA API within <a href="https://github.com/ModelEarth/USEEIO/tree/import_factors/import_factors_exio">generate_import_factors.py</a> generate Sector.csv with 2 to 5 character SectorID and SectorName column.<br><br>

The following YAML for the SQL insert resides at <a href="https://github.com/ModelEarth/OpenFootprint/blob/main/impacts/exiobase/US-source/create-database.yaml">OpenFootprint/impacts/exibase/US-source/create-database.yaml</a>
<!--
import yaml
import pandas as pd
import sqlalchemy
from sqlalchemy import create_engine, Table, MetaData

# Load the YAML file
with open('create-database.yaml', 'r') as file:
    config = yaml.safe_load(file)

# Create SQL Alchemy Engine
engine = create_engine('sqlite:///example.db')
metadata = MetaData()

# Function to convert column names to CamelCase without underscores
def to_camel_case(snake_str):
    components = snake_str.split('_')
    return components[0].capitalize() + ''.join(x.title() for x in components[1:])

# Process each table in the YAML configuration
for table_name, table_config in config.items():
    csv_file = table_config['source']
    df = pd.read_csv(csv_file)

    columns_map = table_config.get('columns', {})
    omit_columns = table_config.get('omit', [])

    # Drop omitted columns
    df.drop(columns=omit_columns, errors='ignore', inplace=True)

    # Rename columns as per the YAML configuration
    df.rename(columns=columns_map, inplace=True)

    # Generate new column names for remaining columns
    new_columns = {}
    for col in df.columns:
        if col not in columns_map.values():
            new_columns[col] = to_camel_case(col)
    df.rename(columns=new_columns, inplace=True)

    # Exclude 'Year' column if not explicitly included in columns_map
    if 'Year' not in columns_map.values() and 'Year' in df.columns:
        df.drop(columns=['Year'], inplace=True)

    # Append "US" to the table name
    table_name = table_name + "US"

    # Insert/Update the data into the database
    if engine.dialect.has_table(engine, table_name):
        # Update existing table
        temp_table_name = table_name + "_temp"
        df.to_sql(temp_table_name, engine, if_exists='replace', index=False)
        with engine.connect() as conn:
            conn.execute(f"""
                INSERT OR REPLACE INTO {table_name}
                SELECT * FROM {temp_table_name}
            """)
            conn.execute(f"DROP TABLE {temp_table_name}")
    else:
        # Create and insert new table
        df.to_sql(table_name, engine, if_exists='replace', index=False)
-->

<pre class="yamlPre">
<div id="yamlDiv"></div>
</pre>

<div id="readmeDiv"></div>
</div>

</body>
</html>